{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db305d7-3f18-43b8-a961-0cfa79284639",
   "metadata": {},
   "source": [
    "# Chapter 5 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f80642-11b4-4bf5-a263-32b920a92b72",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae63e7c-cc00-481d-beab-b3588fe3c7f9",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f27e73b3-2186-43cf-b7ce-35a80ce058ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import arviz as az\n",
    "import graphviz as gr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.interpolate import BSpline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f5cae-1e85-4013-878e-78ce3b9de9ce",
   "metadata": {},
   "source": [
    "### Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61fe68b-59fc-4915-90e0-1e4a4d8f7a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seaborn defaults\n",
    "sns.set(\n",
    "    style=\"whitegrid\",\n",
    "    font_scale=1.2,\n",
    "    rc={\n",
    "        \"axes.edgecolor\": \"0\",\n",
    "        \"axes.grid.which\": \"both\",\n",
    "        \"axes.labelcolor\": \"0\",\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "colors = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d545d-8886-40e4-b6b6-52d52d50e5af",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a09aea4-58d5-44f5-9267-160437fb6d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "HOWELL_FILE = \"howell.csv\"\n",
    "CHERRY_BLOSSOMS_FILE = \"cherry_blossoms.csv\"\n",
    "WAFFLE_DIVORCE_FILE = \"waffle_divorce.csv\"\n",
    "MILK_FILE = \"milk.csv\"\n",
    "LDS_FILE = \"lds_by_state.csv\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbac1ab-add4-4555-962f-e4a500b084a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_name, data_dir=DATA_DIR, **kwargs):\n",
    "    path = os.path.join(data_dir, file_name)\n",
    "    return pd.read_csv(path, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f5d9d-208e-430c-b7b2-dd43bb7f1650",
   "metadata": {},
   "source": [
    "## Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9185b89-e103-4477-967e-0d66b42a5bfd",
   "metadata": {},
   "source": [
    "### 5E1\n",
    "\n",
    "Which of the linear models below are multiple linear regressions?\n",
    "1. $\\mu_i = \\alpha + \\beta x_i$\n",
    "2. $\\mu_i = \\beta_x x_i + \\beta_z z_i$\n",
    "3. $\\mu_i = \\alpha + \\beta (x_i - z_i)$\n",
    "4. $\\mu_i = \\alpha + \\beta_x x_i + \\beta_z z_i$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f6d82-ce54-4d22-807f-737deca83656",
   "metadata": {},
   "source": [
    "2 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513f0f2-f162-4ae8-a3da-871478f16a68",
   "metadata": {},
   "source": [
    "### 5E2\n",
    "\n",
    "Write down a multiple regression to evaluate the claim: Animal diversity is linearly related to latitude, but only after controlling for plant diversity.\n",
    "You just need to write down the model definition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e06d6-f152-4877-97d1-5cfebc5d524c",
   "metadata": {},
   "source": [
    "Let `A`, `L`, and `P` denote animal diversity, latitute, and plant diversity, respectively. Then the model is\n",
    "\n",
    "\\begin{align}\n",
    "    A_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "    \\mu_i & = \\alpha + \\beta_L L_i + \\beta_P P_i.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d75bb6-49ba-4938-ace7-33c6b3618a04",
   "metadata": {},
   "source": [
    "### 5E3\n",
    "\n",
    "Write down a multiple regression to evaluate the claim: Neither amount of funding nor size of laboratory is by itself a good predictor of time to PhD degree; but together these variables are both positively associated with time to degree.\n",
    "Write down the model definition and indicate which side of zero each slope parameter should be on.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0513297-6d4d-4637-a985-3742c885791a",
   "metadata": {},
   "source": [
    "Let `T`, `F`, and `L` denote time to PhD, amount of funding, and size of laboratory, respectively. Then the model is\n",
    "\n",
    "\\begin{align}\n",
    "    T_i & \\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n",
    "    \\mu_i & = \\alpha + \\beta_F F_i + \\beta_L L_i.\n",
    "\\end{align}\n",
    "\n",
    "If together both are positively associated with time to degree then both $\\beta_F$ and $\\beta_L$ should be positive.\n",
    "If neither is a good predictor on its own then I expect that they are negatively associated with each other; that is, larger laboratories have less funding per student."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99e07d-cb55-498c-b558-bca60831c6cf",
   "metadata": {},
   "source": [
    "### 5E4\n",
    "\n",
    "Suppose you have a single categorical predictor with 4 levels (unique values), labeled A, B, C and D.\n",
    "Let $A_i$ be an indicator variable that is 1 where case $i$ is in category A. Also suppose $B_i$, $C_i$, and $D_i$ for the other categories.\n",
    "Now which of the following linear models are inferentially equivalent ways to include the categorical variable in a regression?\n",
    "Models are inferentially equivalent when it’s possible to compute one posterior distribution from the posterior distribution of another model.\n",
    "1. $\\mu_i = \\alpha + \\beta_A A_i + \\beta_B B_i + \\beta_D D_i$\n",
    "2. $\\mu_i = \\alpha + \\beta_A A_i + \\beta_B B_i + \\beta_C C_i + \\beta_D D_i$\n",
    "3. $\\mu_i = \\alpha + \\beta_B B_i + \\beta_C C_i + \\beta_D D_i$\n",
    "4. $\\mu_i = \\alpha_A A_i + \\alpha_B B_i + \\alpha_C C_i + \\alpha_D D_i$\n",
    "5. $\\mu_i = \\alpha_A (1 - B_i - C_i - D_i) + \\alpha_B B_i + \\alpha_C C_i + \\alpha_D D_i$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ccc2d-f126-42c6-9a03-dbbc31c052d8",
   "metadata": {},
   "source": [
    "All the models except (2) are inferrentially equivalent: since each case must belong to one of the categories, $A_i + B_i + C_i + D_i = 1$, and so any models that contain exactly four out of $A_i$, $B_i$, $C_i$, $D_i$, and a constant term are inferentially equivalent.\n",
    "It is possible to compute the posterior distribution of any of the models from that of (2), but not the other way round.\n",
    "To illustrate this suppose that we $alpha \\sim \\text{Uniform}(0, 1)$ and $\\alpha = \\beta + \\gamma$.\n",
    "It is possible that $\\beta \\sim \\text{Uniform}(0, x)$ and $\\gamma \\sim \\text{Uniform}(x, 1)$ for any $x \\in  (0, 1)$, so the distributions of $\\beta$ and $\\gamma$ are not uniquely determined by that of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b105392-c09c-4079-a483-c4b21b4d3da2",
   "metadata": {},
   "source": [
    "## Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d9e61-4c9d-4300-ae60-d76d4e131040",
   "metadata": {},
   "source": [
    "### 5M1\n",
    "\n",
    "Invent your own example of a spurious correlation.\n",
    "An outcome variable should be correlated with both predictor variables.\n",
    "But when both predictors are entered in the same model, the correlation between the outcome and one of the predictors should mostly vanish (or at least be greatly reduced).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30d141a-3836-4b91-8c5f-9808c33a7560",
   "metadata": {},
   "source": [
    "Generate sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893341e8-90e1-4d58-89ac-5f4996d72885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise(x, size, scale):\n",
    "    return x + +stats.norm.rvs(loc=0, scale=scale, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2f54762-3667-4661-b6b4-72565114f0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "x1 = np.linspace(-2, 2, n_samples)\n",
    "x1 = add_noise(x1, n_samples, 0.5)\n",
    "\n",
    "x2 = 2 * x1 - 1\n",
    "x2 = add_noise(x2, n_samples, 0.5)\n",
    "\n",
    "y = 0.5 * x1 + 1\n",
    "y = add_noise(y, n_samples, 0.5)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"y\": y,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c997681-c93d-423c-a675-4b6d836658e2",
   "metadata": {},
   "source": [
    "First model the outcome as a linear function of the individual predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b78537-db14-40c8-b1ff-858e319ee797",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta1, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:00&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m_5m1a:\n",
    "    # data\n",
    "    x1 = pm.MutableData(\"x1\", data.x1, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta1 * x1, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m1a = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "with pm.Model() as m_5m1b:\n",
    "    # data\n",
    "    x2 = pm.MutableData(\"x2\", data.x2, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta2 = pm.Normal(\"beta2\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta2 * x2, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m1b = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135eaa71-776a-4ca8-bf9e-fd6f5ecef6d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Plot the posterior predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453eab66-6762-4992-a03d-aa0e0c756f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_posterior_lines(trace, predictor, hdi_prob=0.89, ax=None):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # plot data\n",
    "    sns.scatterplot(\n",
    "        x=trace.constant_data[predictor],\n",
    "        y=trace.observed_data.y,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # plot mean line\n",
    "    ax.plot(\n",
    "        trace.constant_data[predictor],\n",
    "        trace.posterior.mu.mean(dim=[\"chain\", \"draw\"]),\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    # plot HDI on mu\n",
    "    mu_hdi = az.hdi(trace.posterior.mu, hdi_prob=hdi_prob)\n",
    "    mu_hdi = pd.DataFrame(\n",
    "        {\n",
    "            predictor: trace.constant_data[predictor],\n",
    "            \"lower\": mu_hdi.mu.sel(hdi=\"lower\"),\n",
    "            \"higher\": mu_hdi.mu.sel(hdi=\"higher\"),\n",
    "        }\n",
    "    ).sort_values(predictor)\n",
    "\n",
    "    ax.fill_between(\n",
    "        mu_hdi[predictor],\n",
    "        mu_hdi[\"lower\"],\n",
    "        mu_hdi[\"higher\"],\n",
    "        color=\"k\",\n",
    "        alpha=0.3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03b8f6-73ad-4b29-bccb-2cf241736689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 4))\n",
    "\n",
    "plot_posterior_lines(trace_5m1a, \"x1\", ax=axs[0])\n",
    "plot_posterior_lines(trace_5m1b, \"x2\", ax=axs[1])\n",
    "\n",
    "fig.suptitle(\"Single predictor variable\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265aa2a9-31c5-46ab-84fe-f864924b848e",
   "metadata": {},
   "source": [
    "There are very clear associations.\n",
    "\n",
    "Now generate a multiple linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c57aa7-97c4-4a34-b925-14ed74dd0ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pm.Model() as m_5m1c:\n",
    "    # data\n",
    "    x1 = pm.MutableData(\"x1\", data.x1, dims=\"obs\")\n",
    "    x2 = pm.MutableData(\"x2\", data.x2, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n",
    "    beta2 = pm.Normal(\"beta2\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta1 * x1 + beta2 * x2, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m1c = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a84f712-b371-48d6-a7c1-b38c61d93488",
   "metadata": {},
   "source": [
    "The easiest thing to do it to compare the posterior distributions for the $\\beta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008078d4-4bfa-426a-a0f3-6050afb55cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_5m1a, trace_5m1b, trace_5m1c],\n",
    "    model_names=[\"5m1a\", \"5m1b\", \"5m1c\"],\n",
    "    var_names=[\"beta\"],\n",
    "    filter_vars=\"regex\",\n",
    "    combined=True,\n",
    "    hdi_prob=0.89,\n",
    "    figsize=(5, 2),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f6234-078d-4eb2-a592-6de1fd34e742",
   "metadata": {},
   "source": [
    "You can see that $\\beta_2$ becomes centered at 0 once we include $x_1$ in the model.\n",
    "\n",
    "We can also plot what happens in the multivariable model if we hold one variable constant and vary the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a949078-3c34-47d0-bdc8-7875077b7ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_predictions_holding_other_variables_constant(\n",
    "    model, trace, predictor, n_samples=100, hdi_prob=0.89, ax=None\n",
    "):\n",
    "    with model:\n",
    "        predictor_min = trace.constant_data[predictor].min().item()\n",
    "        predictor_max = trace.constant_data[predictor].max().item()\n",
    "\n",
    "        all_variables = list(trace_5m1c.constant_data.data_vars.keys())\n",
    "        new_data = pd.DataFrame(columns=all_variables)\n",
    "        new_data[predictor] = np.linspace(\n",
    "            predictor_min, predictor_max, n_samples  # - 0.25,  # + 0.25,\n",
    "        )\n",
    "        new_data = new_data.fillna(0)\n",
    "\n",
    "        pm.set_data({var: new_data[var] for var in all_variables})\n",
    "        pp_trace = pm.sample_posterior_predictive(\n",
    "            trace,\n",
    "            var_names=[\"mu\", \"y\"],\n",
    "            predictions=True,\n",
    "            random_seed=RANDOM_SEED,\n",
    "        )\n",
    "\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # plot mean line\n",
    "    ax.plot(\n",
    "        pp_trace.predictions_constant_data[predictor],\n",
    "        pp_trace.predictions.mu.mean(dim=[\"chain\", \"draw\"]),\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    # plot HDI on mu\n",
    "    mu_hdi = az.hdi(pp_trace.predictions.mu, hdi_prob=hdi_prob)\n",
    "    mu_hdi = pd.DataFrame(\n",
    "        {\n",
    "            predictor: pp_trace.predictions_constant_data[predictor],\n",
    "            \"lower\": mu_hdi.mu.sel(hdi=\"lower\"),\n",
    "            \"higher\": mu_hdi.mu.sel(hdi=\"higher\"),\n",
    "        }\n",
    "    ).sort_values(predictor)\n",
    "\n",
    "    ax.fill_between(\n",
    "        mu_hdi[predictor],\n",
    "        mu_hdi[\"lower\"],\n",
    "        mu_hdi[\"higher\"],\n",
    "        color=\"k\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=predictor,\n",
    "        ylabel=\"y\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e04ef-d2db-4b1b-bd56-b79de99c9212",
   "metadata": {},
   "source": [
    "Let's plot all of this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2f340-8aab-40d4-8b82-fbe77dbfb909",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "\n",
    "# first plot the single predictor models\n",
    "plot_posterior_lines(trace_5m1a, \"x1\", ax=axs[0, 0])\n",
    "axs[0, 0].set(xlabel=None, title=\"Single regression on x1\")\n",
    "axs[0, 0].tick_params(labelbottom=False)\n",
    "\n",
    "plot_posterior_lines(trace_5m1b, \"x2\", ax=axs[0, 1])\n",
    "axs[0, 1].set(xlabel=None, ylabel=None, title=\"Single regression on x2\")\n",
    "axs[0, 1].tick_params(labelbottom=False)\n",
    "\n",
    "# now the multiple regression model\n",
    "plot_predictions_holding_other_variables_constant(\n",
    "    m_5m1c, trace_5m1c, \"x1\", ax=axs[1, 0]\n",
    ")\n",
    "axs[1, 0].set(title=\"Multiple regression holding x2 = 0\")\n",
    "\n",
    "plot_predictions_holding_other_variables_constant(\n",
    "    m_5m1c, trace_5m1c, \"x2\", ax=axs[1, 1]\n",
    ")\n",
    "axs[1, 1].set(ylabel=None, title=\"Multiple regression holding x1 = 0\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbc3d7-637c-4aca-ad3d-2d3ded0f886a",
   "metadata": {},
   "source": [
    "### 5M2\n",
    "\n",
    "Invent your own example of a masked relationship.\n",
    "An outcome variable should be correlated with both predictor variables, but in opposite directions.\n",
    "And the two predictor variables should be correlated with one another.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198e478-c425-4930-a074-951bf44248a3",
   "metadata": {},
   "source": [
    "This is pretty similar to the previous example so I'll skip most of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d35964-086d-4100-beb1-88d2d5f44d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_noise(x, size, scale):\n",
    "    return x + +stats.norm.rvs(loc=0, scale=scale, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b71768-9ea1-4e0f-96db-bd12f0b0c3d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "\n",
    "x1 = np.linspace(-2, 2, n_samples)\n",
    "x1 = add_noise(x1, n_samples, 0.5)\n",
    "\n",
    "x2 = np.linspace(-4, 4, n_samples)\n",
    "x2 = add_noise(x2, n_samples, 0.5)\n",
    "\n",
    "y = 2 * x1 - x2 + 1\n",
    "y = add_noise(y, n_samples, 0.1)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"y\": y,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614d616-fd46-43ba-8777-41ca2d2a0190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pm.Model() as m_5m2a:\n",
    "    # data\n",
    "    x1 = pm.MutableData(\"x1\", data.x1, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta1 * x1, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m2a = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "with pm.Model() as m_5m2b:\n",
    "    # data\n",
    "    x2 = pm.MutableData(\"x2\", data.x2, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta2 = pm.Normal(\"beta2\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta2 * x2, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m2b = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "with pm.Model() as m_5m2c:\n",
    "    # data\n",
    "    x1 = pm.MutableData(\"x1\", data.x1, dims=\"obs\")\n",
    "    x2 = pm.MutableData(\"x2\", data.x2, dims=\"obs\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=2)\n",
    "    beta1 = pm.Normal(\"beta1\", mu=0, sigma=2)\n",
    "    beta2 = pm.Normal(\"beta2\", mu=0, sigma=2)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta1 * x1 + beta2 * x2, dims=\"obs\")\n",
    "\n",
    "    # likelihood\n",
    "    y_pm = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data.y, dims=\"obs\")\n",
    "\n",
    "    # sample\n",
    "    trace_5m2c = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59332155-efb9-4283-aa8a-bde23a86cd17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.plot_forest(\n",
    "    [trace_5m2a, trace_5m2b, trace_5m2c],\n",
    "    model_names=[\"5m2a\", \"5m2b\", \"5m2c\"],\n",
    "    var_names=[\"beta\"],\n",
    "    filter_vars=\"regex\",\n",
    "    combined=True,\n",
    "    hdi_prob=0.89,\n",
    "    figsize=(5, 2),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a2e99-d2fe-49ea-b8be-fd88d4dc3c60",
   "metadata": {},
   "source": [
    "The coefficients in the single regressions are very close to zero, but in the multiple regression they are significantly non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1939986-2900-43fc-b6c3-09d74ee82b97",
   "metadata": {},
   "source": [
    "### 5M3\n",
    "\n",
    "It is sometimes observed that the best predictor of fire risk is the presence of firefighters—States and localities with many firefighters also have more fires.\n",
    "Presumably firefighters do not cause fires.\n",
    "Nevertheless, this is not a spurious correlation.\n",
    "Instead fires cause firefighters.\n",
    "Consider the same reversal of causal inference in the context of the divorce and marriage data.\n",
    "How might a high divorce rate cause a higher marriage rate?\n",
    "Can you think of a way to evaluate this relationship, using multiple regression?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45be07-7266-4665-b1c3-cd2cf244dddd",
   "metadata": {},
   "source": [
    "People who are currently married can't get married again, so having a high divorce rate could cause a higher marriage rate.\n",
    "For example, in a state in which many people get divorced, the average number of marriages per person may be above one, which wouldn't be possible in a state with very few divorces.\n",
    "\n",
    "Recall that our current model is $D \\leftarrow A \\rightarrow M$ since we concluded that $D$ and $M$ were conditionally independent given $A$.\n",
    "To evaluate the effect of $D$ on $M$ we could make $M$ our outcome variable and model it using regression on $A$ and $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4c1c1-13dd-470e-a49f-1fc2ab991cc1",
   "metadata": {},
   "source": [
    "### 5M4\n",
    "\n",
    "In the divorce data, States with high numbers of members of the Church of Jesus Christ of Latter-day Saints (LDS) have much lower divorce rates than the regression models expected.\n",
    "Find a list of LDS population by State and use those numbers as a predictor variable, predicting divorce rate using marriage rate, median age at marriage, and percent LDS population (possibly standardized).\n",
    "You may want to consider transformations of the raw percent LDS variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc756a-c723-435b-b565-769dcea22b2e",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92d38d-b613-47ba-8669-b2705b1f4e16",
   "metadata": {},
   "source": [
    "We pull data from WorldAtlas from 2020 ([source](https://www.worldatlas.com/articles/mormon-population-by-state.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d2f8a-237d-4c17-85cd-3ad1d519be9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lds = load_data(LDS_FILE, index_col=0)\n",
    "waffle = load_data(WAFFLE_DIVORCE_FILE, delimiter=\";\")\n",
    "\n",
    "# merge the two\n",
    "waffle_lds = waffle.merge(\n",
    "    lds,\n",
    "    how=\"outer\",\n",
    "    left_on=\"Location\",\n",
    "    right_on=\"State\",\n",
    "    validate=\"one_to_one\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f56708-7007-4a5f-98f9-56b8f75cb60a",
   "metadata": {},
   "source": [
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b8272-a8a3-417a-96bb-d48951413025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waffle_lds[[\"Location\", \"Population\", \"State\", \"Total State Population\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c49b9a-415c-4aba-8f94-86b32ac7c030",
   "metadata": {},
   "source": [
    "The `waffle` data is missing a row for Nevada and the `lds` population figures are slightly larger (the data is probably more recent), but not enough to matter too much.\n",
    "We'll drop Nevada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc962bd7-530f-4c43-91fe-03ff08e80e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waffle_lds = waffle_lds.dropna(subset=[\"Location\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5b40b-3b0c-40ed-89e8-89952893b193",
   "metadata": {},
   "source": [
    "Let's take a closer look at the 'Proportion of Mormon Residents' data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecf1ac-4402-43e3-8a59-9e98e5975913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.ecdfplot(waffle_lds, x=\"Proportion of Mormon Residents\", ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8acc74-15c9-4c2e-a942-11fdb2b63b99",
   "metadata": {},
   "source": [
    "This distribution is wild because Utah (and Idaho) have much higher proportion of LDS members.\n",
    "To make this more tractable we'll take the log of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca226cb-02b7-4ced-bc10-2beb160653eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waffle_lds[\"Log Proportion of Mormon Residents\"] = np.log(\n",
    "    waffle_lds[\"Proportion of Mormon Residents\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d685735-1952-48d7-a156-d3fc45980b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.ecdfplot(waffle_lds, x=\"Log Proportion of Mormon Residents\", ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727be009-547a-4ecf-b70e-88a431326de9",
   "metadata": {},
   "source": [
    "This looks much more reasonable.\n",
    "Finally let's standardise the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0aee40-7f8b-43d5-a7e1-cb33b52c59a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standardise variables\n",
    "waffle_lds_normaliser = StandardScaler()\n",
    "waffle_lds[\n",
    "    [\"divorce\", \"marriage\", \"age\", \"log_prop_lds\"]\n",
    "] = waffle_lds_normaliser.fit_transform(\n",
    "    waffle_lds[\n",
    "        [\n",
    "            \"Divorce\",\n",
    "            \"Marriage\",\n",
    "            \"MedianAgeMarriage\",\n",
    "            \"Log Proportion of Mormon Residents\",\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b754e92e-d663-409f-a0f9-e9f5d8e5df79",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e0691-030a-4370-a3a1-0fb92a029097",
   "metadata": {},
   "source": [
    "Begin by redefining the original model without the LDS variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa583f-f8db-46eb-9eb2-3a0209e4cb0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pm.Model() as m5_3:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2)\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=0.5)\n",
    "    beta_marriage = pm.Normal(\"beta_marriage\", mu=0, sigma=0.5)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle_lds.age, dims=\"state\")\n",
    "    marriage = pm.MutableData(\"marriage\", waffle_lds.marriage, dims=\"state\")\n",
    "    log_prop_lds = pm.MutableData(\"log_prop_lds\", waffle_lds.log_prop_lds, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\n",
    "        \"mu\", alpha + beta_age * age + beta_marriage * marriage, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle_lds.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # sample\n",
    "    trace_5_3 = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e485f39-b9e5-4f16-94fd-ef51b5b2fcdd",
   "metadata": {},
   "source": [
    "Let's plot the residuals against the log proportion of LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36142b-524d-4671-9b29-d0860ce40af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_posterior_residuals_against_log_prop_lds(trace, hdi_prob=0.89, ax=None):\n",
    "    # add the residual\n",
    "    trace.posterior[\"residual\"] = trace.observed_data.divorce - trace.posterior.mu\n",
    "\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # plot residuals against log prop lds\n",
    "    sns.scatterplot(\n",
    "        x=trace.constant_data.log_prop_lds,\n",
    "        y=trace.posterior.residual.mean(dim=[\"chain\", \"draw\"]),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # plot HDI\n",
    "    residuals_hdi = az.hdi(trace.posterior.residual, hdi_prob=hdi_prob)\n",
    "    ax.plot(\n",
    "        [\n",
    "            trace.constant_data.log_prop_lds,\n",
    "            trace.constant_data.log_prop_lds,\n",
    "        ],\n",
    "        residuals_hdi.residual.T,\n",
    "        color=colors[0],\n",
    "        lw=0.8,\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"Log proportion LDS\",\n",
    "        ylabel=\"Residual\",\n",
    "        title=\"Posterior residuals against log prop LDS\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f9ce0-1a15-4206-b0d5-eb540b929e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_posterior_residuals_against_log_prop_lds(trace_5_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1692e-4441-46b6-afd4-593ec84474ca",
   "metadata": {},
   "source": [
    "It's clear that the two points to the furthest right (Idaha and Utah) are underpredicted but harder to see if there's a general trend.\n",
    "\n",
    "Let's recreate the model with the additional predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987847b8-39b9-412e-878b-b24d25c6bf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with pm.Model() as m_5m4:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2)\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=0.5)\n",
    "    beta_marriage = pm.Normal(\"beta_marriage\", mu=0, sigma=0.5)\n",
    "    beta_log_prop_lds = pm.Normal(\"beta_log_prop_lds\", mu=0, sigma=0.5)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle_lds.age, dims=\"state\")\n",
    "    marriage = pm.MutableData(\"marriage\", waffle_lds.marriage, dims=\"state\")\n",
    "    log_prop_lds = pm.MutableData(\"log_prop_lds\", waffle_lds.log_prop_lds, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\n",
    "        \"mu\",\n",
    "        alpha\n",
    "        + beta_age * age\n",
    "        + beta_marriage * marriage\n",
    "        + beta_log_prop_lds * log_prop_lds,\n",
    "        dims=\"state\",\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle_lds.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # sample\n",
    "    trace_5m4 = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11479672-5b1e-46dd-955e-4745e8c70d58",
   "metadata": {},
   "source": [
    "Let's compare the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f45612a-cba9-409f-97ee-057735b2454d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    [trace_5_3, trace_5m4],\n",
    "    model_names=[\"m5_3\", \"m_5m4\"],\n",
    "    var_names=[\"alpha\", \"beta\"],\n",
    "    filter_vars=\"regex\",\n",
    "    hdi_prob=0.89,\n",
    "    combined=True,\n",
    "    figsize=(6, 3),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2aa151-d25b-4368-92e1-a60586886c3e",
   "metadata": {},
   "source": [
    "The log proportion of LDS in each state does seem to have a non-zero weight which implies that it adds extra explanatory power on top of the existing variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a99bd4-afd5-450d-b69d-cbeaa769695f",
   "metadata": {},
   "source": [
    "Let's compare the posterior predictions for each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7d57b-15e5-4091-8fa1-0efd11885f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_divorce_posterior_predictions(trace, hdi_prob=0.89, ax=None):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # predicted against observed\n",
    "    sns.scatterplot(\n",
    "        x=trace.observed_data.divorce,\n",
    "        y=trace.posterior.mu.mean(dim=[\"chain\", \"draw\"]),\n",
    "        facecolors=\"none\",\n",
    "        edgecolor=colors[0],\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # add hdi\n",
    "    mu_hdi = az.hdi(trace.posterior.mu, hdi_prob=hdi_prob)\n",
    "    ax.plot(\n",
    "        [\n",
    "            trace.observed_data.divorce,\n",
    "            trace.observed_data.divorce,\n",
    "        ],\n",
    "        mu_hdi.mu.T,\n",
    "        color=colors[0],\n",
    "        lw=0.8,\n",
    "    )\n",
    "\n",
    "    # true value line\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    diag_line_vals = np.linspace(\n",
    "        np.array(xlim[0], ylim[0]).max(),\n",
    "        np.array(xlim[1], ylim[1]).min(),\n",
    "        100,\n",
    "    )\n",
    "    ax.plot(\n",
    "        diag_line_vals,\n",
    "        diag_line_vals,\n",
    "        ls=\"--\",\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"Observed divorce\",\n",
    "        ylabel=\"Predicted divorce\",\n",
    "        title=\"Posterior prediction plot\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90822d99-0673-4554-bfd7-5f94e929d056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "plot_divorce_posterior_predictions(trace_5_3, ax=axs[0])\n",
    "plot_divorce_posterior_predictions(trace_5m4, ax=axs[1])\n",
    "\n",
    "axs[0].set_title(\"Excluding proportion LDS\")\n",
    "axs[1].set_title(\"Including proportion LDS\")\n",
    "\n",
    "fig.suptitle(\"Posterior prediction plots\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dc095-4041-4f19-afbe-1084028d51c1",
   "metadata": {},
   "source": [
    "Let's recreate the earlier plot but with this new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad58ac3-bbb0-46d3-869b-6b981195dc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 5))\n",
    "\n",
    "plot_posterior_residuals_against_log_prop_lds(trace_5_3, ax=axs[0])\n",
    "plot_posterior_residuals_against_log_prop_lds(trace_5m4, ax=axs[1])\n",
    "\n",
    "axs[0].set_title(\"Excluding proportion LDS\")\n",
    "axs[1].set_title(\"Including proportion LDS\")\n",
    "\n",
    "fig.suptitle(\"Posterior residuals against log proportion LDS\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d526ca0-7d7e-422d-b04d-6c275534ff21",
   "metadata": {},
   "source": [
    "### 5M5\n",
    "\n",
    "One way to reason through multiple causation hypotheses is to imagine detailed mechanisms through which predictor variables may influence outcomes.\n",
    "For example, it is sometimes argued that the price of gasoline (predictor variable) is positively associated with lower obesity rates (outcome variable).\n",
    "However, there are at least two important mechanisms by which the price of gas could reduce obesity.\n",
    "First, it could lead to less driving and therefore more exercise.\n",
    "Second, it could lead to less driving, which leads to less eating out, which leads to less consumption of huge restaurant meals.\n",
    "Can you outline one or more multiple regressions that address these two mechanisms?\n",
    "Assume you can have any predictor data you need.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6eaba-25ce-461b-8ded-bb902b58f45b",
   "metadata": {},
   "source": [
    "Let $G$, $D$, $E$, and $O$ denote gas price, amount of driving, level of eating out, and obesity respectively.\n",
    "The overall relationship of interest is $G \\to O$.\n",
    "\n",
    "The first mechanism argues for a causal influence $G \\to D \\to O$.\n",
    "We could address this with a multiple regression of $O$ on $G$ and $D$ and compare this with a single regression of $O$ on $G$.\n",
    "The question to address is whether $D$ adds any explanatory power with $G$ also in the model.\n",
    "\n",
    "The second mechanism argues for a causal influence $D \\to E \\to O$.\n",
    "Again, this can be analysis by regressing $O$ on $D$ and $E$ and comparing with a regression of $O$ on $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e906ef6-a2b7-4691-9c79-71ef460b8346",
   "metadata": {},
   "source": [
    "## Hard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2e81a-f007-470b-b596-0aca4a04693f",
   "metadata": {},
   "source": [
    "### 5H1\n",
    "\n",
    "In the divorce example, suppose the DAG is: $M \\to A \\to D$.\n",
    "What are the implied conditional independencies of the graph?\n",
    "Are the data consistent with it?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a607ebb-d7d9-4cce-bc26-4afee5efbcd5",
   "metadata": {},
   "source": [
    "Since there is no direct arrow from $M$ to $D$, this implies that $D$ is conditionally independent of $M$, given $A$.\n",
    "\n",
    "The data are consistent with this DAG; in a multiple regression of $D$ on $A$ and $M$, there is little predictive power in $M$.\n",
    "This is consistent with the claim that $D$ is conditionally independent of $M$ given $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367c3c4-4b43-4f5d-a0e2-e2a3a8ba6acc",
   "metadata": {},
   "source": [
    "### 5H2\n",
    "\n",
    "Assuming that the DAG for the divorce example is indeed $M \\to A \\to D$, fit a new model and use it to estimate the counterfactual effect of halving a State’s marriage rate $M$.\n",
    "Using the counterfactual example from the chapter (starting on page 140) as a template.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6e222a-52e4-4e9a-81b8-da6daa84edb8",
   "metadata": {},
   "source": [
    "Since there is no direct causal arrow from $M$ to $D$, all we need to do is to model $A$ as a linear function of $M$, and $D$ as a function of $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436d9d2-600b-4ec2-a976-47278865f9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "waffle = load_data(WAFFLE_DIVORCE_FILE, delimiter=\";\")\n",
    "\n",
    "# standardise variables\n",
    "waffle_normaliser = StandardScaler().set_output(transform=\"pandas\")\n",
    "waffle[[\"divorce\", \"marriage\", \"age\"]] = waffle_normaliser.fit_transform(\n",
    "    waffle[[\"Divorce\", \"Marriage\", \"MedianAgeMarriage\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2865d-4c62-4a89-943c-1a16f2b9c382",
   "metadata": {},
   "source": [
    "Define the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2ebe1-2bbd-4015-8516-dda64a9ae040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = {\n",
    "    \"state\": waffle.Location,\n",
    "    \"outcome\": [\"age\", \"divorce\"],\n",
    "}\n",
    "with pm.Model(coords=coords) as m_5h2:\n",
    "    # data\n",
    "    marriage = pm.MutableData(\"marriage\", waffle.marriage, dims=\"state\")\n",
    "\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2, dims=\"outcome\")\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=0.5, dims=\"outcome\")\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1, dims=\"outcome\")\n",
    "\n",
    "    # mu model\n",
    "    mu_age = pm.Deterministic(\"mu_age\", alpha[0] + beta[0] * marriage, dims=\"state\")\n",
    "    age = pm.Normal(\"age\", mu=mu_age, sigma=sigma[0], observed=waffle.age, dims=\"state\")\n",
    "\n",
    "    # divorce model\n",
    "    mu_divorce = pm.Deterministic(\"mu_divorce\", alpha[1] + beta[1] * age, dims=\"state\")\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu_divorce, sigma=sigma[1], observed=waffle.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # sample prior\n",
    "    trace_5h2 = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d700a-3f6a-4ead-8ead-47086cdb94a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_5h2.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb183ccc-39f2-49c4-ad4f-50dcf3753054",
   "metadata": {},
   "source": [
    "Take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7b478-d5e1-4884-94b8-d4cc405d6d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    trace_5h2,\n",
    "    var_names=[\"~mu\"],\n",
    "    filter_vars=\"regex\",\n",
    "    hdi_prob=0.89,\n",
    "    combined=True,\n",
    "    figsize=(6, 2),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c490f-4d44-463e-9c0b-4dee72e8a68f",
   "metadata": {},
   "source": [
    "I also want to plot the posterior predictions for each of the regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9e709-679a-47fb-9838-0eb6f3d19f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_posterior_predictions(\n",
    "    predictor_data, outcome_data, posterior_data, hdi_prob=0.89, ax=None\n",
    "):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # observed data\n",
    "    sns.scatterplot(\n",
    "        x=predictor_data,\n",
    "        y=outcome_data,\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    # get data to plot posteriors\n",
    "    posterior_name = posterior_data.name\n",
    "    posterior_hdi = az.hdi(posterior_data, hdi_prob=hdi_prob)\n",
    "    plot_data = pd.DataFrame(\n",
    "        {\n",
    "            \"predictor\": predictor_data,\n",
    "            \"mean\": posterior_data.mean(dim=[\"chain\", \"draw\"]),\n",
    "            \"hdi_lower\": posterior_hdi[posterior_name].sel(hdi=\"lower\"),\n",
    "            \"hdi_higher\": posterior_hdi[posterior_name].sel(hdi=\"higher\"),\n",
    "        }\n",
    "    ).sort_values(\"predictor\")\n",
    "\n",
    "    # posterior mean\n",
    "    ax.plot(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"mean\"],\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    # posterior hdi\n",
    "    ax.fill_between(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"hdi_lower\"],\n",
    "        plot_data[\"hdi_higher\"],\n",
    "        color=\"k\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ax.set(title=\"Posterior predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e650b-3a72-4250-bc61-0f1f4b2b93cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "plot_posterior_predictions(\n",
    "    trace_5h2.constant_data.marriage,\n",
    "    trace_5h2.observed_data.age,\n",
    "    trace_5h2.posterior.mu_age,\n",
    "    ax=axs[0],\n",
    ")\n",
    "plot_posterior_predictions(\n",
    "    trace_5h2.observed_data.age,\n",
    "    trace_5h2.observed_data.divorce,\n",
    "    trace_5h2.posterior.mu_divorce,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_title(None)\n",
    "\n",
    "fig.suptitle(\"Univariate regression posterior predictions\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97feaad6-6e05-4f4a-af06-725d62eb2c72",
   "metadata": {},
   "source": [
    "We can then look at the combined model, pulling predicted values for age through to predict divorce values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a5546-4eca-4e5d-a0b5-9d3ce04fefee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with m_5h2:\n",
    "    trace_5h2 = pm.sample_posterior_predictive(\n",
    "        trace_5h2,\n",
    "        var_names=[\"mu_age\", \"age\", \"mu_divorce\", \"divorce\"],\n",
    "        extend_inferencedata=True,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979c71e-e2ef-4bf6-aeee-cd3d1038d0ba",
   "metadata": {},
   "source": [
    "Plot this with HDIs for both $\\mu$ and the posterior divorce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19397cd9-690a-4106-96d9-947e15fd9523",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "plot_posterior_predictions(\n",
    "    trace_5h2.constant_data.marriage,\n",
    "    trace_5h2.observed_data.divorce,\n",
    "    trace_5h2.posterior_predictive.mu_divorce,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "divorce_hdi = az.hdi(trace_5h2.posterior_predictive.divorce, hdi_prob=0.89)\n",
    "hdi_data = pd.DataFrame(\n",
    "    {\n",
    "        \"marriage\": trace_5h2.constant_data.marriage,\n",
    "        \"lower\": divorce_hdi.divorce.sel(hdi=\"lower\"),\n",
    "        \"higher\": divorce_hdi.divorce.sel(hdi=\"higher\"),\n",
    "    }\n",
    ").sort_values(\"marriage\")\n",
    "ax.fill_between(\n",
    "    hdi_data.marriage,\n",
    "    hdi_data.lower,\n",
    "    hdi_data.higher,\n",
    "    color=\"k\",\n",
    "    alpha=0.1,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2115f9e-6a3d-47e3-b23e-5b2d61d7042c",
   "metadata": {},
   "source": [
    "Notice that pulling this through has massively increased the uncertainty in $\\mu\\text{[divorce]}$.\n",
    "This is partly because $\\mu\\text{[divorce]}$ depends on the posterior predictive values of age, not just the posterior of $\\mu\\text{[age]}$; that is, the posterior of $\\sigma\\text{[age]}$ contributes to the predictions of $\\mu\\text{[divorce]}$.\n",
    "\n",
    "Now we want to estimate the effect of halving the marriage rate in a State.\n",
    "To generate the counterfactual predictions we first need to normalise the half marriage values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e1c31-9a96-46b5-8c9e-6852fceb72ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate half marriage rates\n",
    "counterfactual_data = pd.DataFrame(columns=waffle_normaliser.feature_names_in_)\n",
    "counterfactual_data[\"Marriage\"] = waffle[\"Marriage\"] / 2\n",
    "\n",
    "# normalise\n",
    "marriage_half = waffle_normaliser.transform(counterfactual_data).Marriage.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099ac28-6a95-46cc-bbdd-c604f535c834",
   "metadata": {},
   "source": [
    "Now generate the counterfactual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe59bc-f57c-42e8-8d8c-4b956c547b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with m_5h2:\n",
    "    pm.set_data({\"marriage\": marriage_half})\n",
    "    trace_5h2 = pm.sample_posterior_predictive(\n",
    "        trace_5h2,\n",
    "        var_names=[\"mu_age\", \"age\", \"mu_divorce\", \"divorce\"],\n",
    "        extend_inferencedata=True,\n",
    "        predictions=True,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ddc52c-f453-491a-97d8-76a8df56e40a",
   "metadata": {},
   "source": [
    "Generating the counterfactual predictions requires making a decision: for a state with marriage rate $m$ and true divorce rate $d$, should we simply use the posterior predictive divorce distribution for marriage rate $\\frac{m}{2}$, or should we look at the difference between the posterior predictive divorce distributions for marriage rates $m$ and $\\frac{m}{2}$ and subtract this from the observed divorce rate $d$.\n",
    "These actually correspond to different modelling assumptions.\n",
    "\n",
    "The first assumes that each State's divorce rate is a random sample from the posterior predictive and if the state was resampled (with a different marriage rate) it would regress towards the mean.\n",
    "This is analogous to rolling a die - if on the first roll we got a value higher than expected, we would still expect the second roll to be centred at the expected value.\n",
    "\n",
    "The second assumes that each State has latent characteristics that explain the difference from the model and that these would remain even if the marriage rate changed.\n",
    "So if a particular State's divorce rate if $x$ above the model's prediction at that marriage rate, then we would expect it to still be $x$ above the model predictions at the new marriage rate.\n",
    "\n",
    "I think the second is a more realistic model of the situation so will use that to generate the counterfactual divorce predictions.\n",
    "That is, I will look at the predicted effect on divorce rate of halving marriage rate for a given marriage rate and apply that to the specific divorce rate for the State."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda0d33-c96f-41ae-a68f-ac5ec2d92f24",
   "metadata": {},
   "source": [
    "First we find the effect on divorce rate of halving marriage rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fccfd-0391-40ef-8a15-5cf144f86dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_5h2.predictions[\"divorce_half_marriage_change\"] = (\n",
    "    trace_5h2.predictions.divorce - trace_5h2.posterior_predictive.divorce\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f6159-7e31-4eb6-94db-eb2cad08586a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now convert this to un-normalised space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276841f5-76f3-47e6-a07a-c80f1e5699a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "divorce_std = np.sqrt(waffle_normaliser.var_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b509ea-7adb-4083-8f57-fff83c963129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waffle[\n",
    "    \"DivorceHalfMarriageChangeMean\"\n",
    "] = divorce_std * trace_5h2.predictions.divorce_half_marriage_change.mean(\n",
    "    dim=[\"chain\", \"draw\"]\n",
    ")\n",
    "\n",
    "hdi = az.hdi(trace_5h2.predictions.divorce_half_marriage_change, hdi_prob=0.89)\n",
    "waffle[\n",
    "    \"DivorceHalfMarriageChangeLower\"\n",
    "] = divorce_std * hdi.divorce_half_marriage_change.sel(hdi=\"lower\")\n",
    "waffle[\n",
    "    \"DivorceHalfMarriageChangeHigher\"\n",
    "] = divorce_std * hdi.divorce_half_marriage_change.sel(hdi=\"higher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4a924-1cad-4bb5-bcce-c3d7f236ecd2",
   "metadata": {},
   "source": [
    "We can plot the effect on divorce rate of halving marriage rate as a function of marriage rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7473a5c-96b8-4c6b-9367-12bf3e803a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "ax.plot(\n",
    "    waffle.sort_values(\"Marriage\")[\"Marriage\"],\n",
    "    waffle.sort_values(\"Marriage\")[\"DivorceHalfMarriageChangeMean\"],\n",
    "    color=\"k\",\n",
    ")\n",
    "\n",
    "ax.fill_between(\n",
    "    waffle.sort_values(\"Marriage\")[\"Marriage\"],\n",
    "    waffle.sort_values(\"Marriage\")[\"DivorceHalfMarriageChangeLower\"],\n",
    "    waffle.sort_values(\"Marriage\")[\"DivorceHalfMarriageChangeHigher\"],\n",
    "    color=\"k\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"Marriage rate\",\n",
    "    ylabel=\"Change in divorce rate\",\n",
    "    title=\"Change in divorce rate from halving marriage rate\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9e11b-1912-463b-9d31-f7a2490bf6c0",
   "metadata": {},
   "source": [
    "Not that this is linear since divorce rate is modelled as a linear function of age which is modelled as a linear function of marriage rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbca10-470a-4079-b198-491336f6c551",
   "metadata": {},
   "source": [
    "Now we plot the expected divorce rate per state as an effect of halving the marriage rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0302f3-03dd-4736-b8c9-802e7e8663e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waffle[\"DivorceHalfMarriageMean\"] = (\n",
    "    waffle[\"Divorce\"] + waffle[\"DivorceHalfMarriageChangeMean\"]\n",
    ")\n",
    "waffle[\"DivorceHalfMarriageLower\"] = (\n",
    "    waffle[\"Divorce\"] + waffle[\"DivorceHalfMarriageChangeLower\"]\n",
    ")\n",
    "waffle[\"DivorceHalfMarriageHigher\"] = (\n",
    "    waffle[\"Divorce\"] + waffle[\"DivorceHalfMarriageChangeHigher\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e34e90-4c04-4329-89a2-ce6a42722910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 14))\n",
    "\n",
    "plot_data = waffle.sort_values(\"Divorce\").reset_index(drop=True)\n",
    "ax.scatter(\n",
    "    plot_data.Divorce,\n",
    "    plot_data.index,\n",
    "    color=colors[0],\n",
    "    label=\"Observed\",\n",
    ")\n",
    "\n",
    "# plot actual divorce rates\n",
    "ax.scatter(\n",
    "    plot_data.DivorceHalfMarriageMean,\n",
    "    plot_data.index,\n",
    "    color=colors[1],\n",
    "    label=\"Counterfactual\",\n",
    ")\n",
    "\n",
    "# counterfactual divorce rates (mean)\n",
    "ax.plot(\n",
    "    plot_data[[\"DivorceHalfMarriageLower\", \"DivorceHalfMarriageHigher\"]].T,\n",
    "    [\n",
    "        plot_data.index,\n",
    "        plot_data.index,\n",
    "    ],\n",
    "    color=colors[1],\n",
    ")\n",
    "\n",
    "# counterfactual divorce rates (HDI)\n",
    "ax.set(\n",
    "    xlabel=\"Divorce Rate\",\n",
    "    yticks=range(plot_data.shape[0]),\n",
    "    yticklabels=plot_data.Location,\n",
    "    title=\"Counterfactual effect of halving marriage rate\",\n",
    "    ylim=[-1, 50],\n",
    ")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac113e5-afad-4877-8d10-dbbfbf7748c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5H3\n",
    "\n",
    "Return to the milk energy model, `m5.7`.\n",
    "Suppose that the true causal relationship among the variables is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e4b07-b44c-4719-baa5-eb0e1c2562ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"M\", \"N\")\n",
    "g.edge(\"M\", \"K\")\n",
    "g.edge(\"N\", \"K\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371813de-4f74-4d6d-8467-7e6e722d9f5c",
   "metadata": {},
   "source": [
    "Now compute the counterfactual effect on $K$ of doubling $M$.\n",
    "You will need to account for both the direct and indirect paths of causation.\n",
    "Use the counterfactual example from the chapter (starting on page 140) as a template.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a0a5a-caad-4931-a591-7ef1b663a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "milk = load_data(MILK_FILE, delimiter=\";\")\n",
    "\n",
    "# get log mass\n",
    "milk[\"log_mass\"] = np.log(milk[\"mass\"])\n",
    "\n",
    "# rename variables\n",
    "milk = milk.rename(\n",
    "    columns={\n",
    "        \"kcal.per.g\": \"kcal_per_g\",\n",
    "        \"neocortex.perc\": \"neocortex_perc\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# standardise variables\n",
    "feature_cols_norm_mapper = {\"kcal_per_g\": \"K\", \"neocortex_perc\": \"N\", \"log_mass\": \"M\"}\n",
    "feature_cols = list(feature_cols_norm_mapper.keys())\n",
    "normed_feature_cols = list(feature_cols_norm_mapper.values())\n",
    "\n",
    "milk_normaliser = StandardScaler().set_output(transform=\"pandas\")\n",
    "milk[normed_feature_cols] = milk_normaliser.fit_transform(milk[feature_cols])\n",
    "\n",
    "# drop missing values\n",
    "milk = milk.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2988fc4-3d67-4372-b65b-fab3b10adbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = {\"species\": milk.species, \"K_feature\": [\"M\", \"N\"]}\n",
    "with pm.Model(coords=coords) as m_5h3:\n",
    "    # data\n",
    "    M = pm.MutableData(\"M\", milk.M, dims=\"species\")\n",
    "\n",
    "    # priors for model M -> N\n",
    "    alpha_N = pm.Normal(\"alpha_N\", mu=0, sigma=0.2)\n",
    "    beta_N = pm.Normal(\"beta_N\", mu=0, sigma=0.5)\n",
    "    sigma_N = pm.Exponential(\"sigma_N\", lam=1)\n",
    "\n",
    "    # model\n",
    "    mu_N = pm.Deterministic(\"mu_N\", alpha_N + beta_N * M, dims=\"species\")\n",
    "\n",
    "    # likelihood\n",
    "    N = pm.Normal(\"N\", mu=mu_N, sigma=sigma_N, observed=milk.N, dims=\"species\")\n",
    "\n",
    "    # priors for M -> K <- N\n",
    "    alpha_K = pm.Normal(\"alpha_K\", mu=0, sigma=0.2)\n",
    "    beta_K = pm.Normal(\"beta_K\", mu=0, sigma=0.5, dims=\"K_feature\")\n",
    "    sigma_K = pm.Exponential(\"sigma_K\", lam=1)\n",
    "\n",
    "    # model\n",
    "    mu_K = pm.Deterministic(\n",
    "        \"mu_K\", alpha_K + beta_K[0] * M + beta_K[1] * N, dims=\"species\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    K = pm.Normal(\"K\", mu=mu_K, sigma=sigma_K, observed=milk.K, dims=\"species\")\n",
    "\n",
    "    # press the inference button!\n",
    "    trace_5h3 = pm.sample(random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2636bb-46ec-4eb7-a622-fb6e0a927bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_5h3.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6b1a2-2b4d-4050-a690-bcb5ad45c787",
   "metadata": {},
   "source": [
    "Take a look at the posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c44b9c-da70-482d-b000-8aa2135ba783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.summary(\n",
    "    trace_5h3,\n",
    "    var_names=[\"~mu\"],\n",
    "    filter_vars=\"regex\",\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    round_to=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407001aa-7e65-4dde-a161-ae181074b598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    trace_5h3,\n",
    "    var_names=[\"~mu\"],\n",
    "    filter_vars=\"regex\",\n",
    "    hdi_prob=0.89,\n",
    "    combined=True,\n",
    "    figsize=(6, 3),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa199cee-3726-4a73-b931-d525d0ff199b",
   "metadata": {},
   "source": [
    "Roughly this is saying that $N$ is positively correlated with $M$ and that $K$ is positively correlated with $N$, but negatively correlated with $M$.\n",
    "So, if $M$ increases by $\\delta$ then $N$ should increase by $0.6\\delta$, and $K$ should increase by $(0.6)^2 \\delta - (0.65) \\delta \\approx -0.3 \\delta$.\n",
    "\n",
    "Let's plot the posterior for the regression of $N$ on $M$ and the posterior predictive for the full model on $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd4ae7-24ed-4593-b8fc-7b448f33fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with m_5h3:\n",
    "    trace_5h3 = pm.sample_posterior_predictive(\n",
    "        trace_5h3,\n",
    "        extend_inferencedata=True,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017034ad-8efe-4b86-9d4e-7d0197b878d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_posterior_predictions(\n",
    "    predictor_data,\n",
    "    posterior_data,\n",
    "    outcome_data=None,\n",
    "    posterior_predictive_data=None,\n",
    "    hdi_prob=0.89,\n",
    "    ax=None,\n",
    "):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    # observed data\n",
    "    if outcome_data is not None:\n",
    "        sns.scatterplot(\n",
    "            x=predictor_data,\n",
    "            y=outcome_data,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "    # get data to plot posteriors\n",
    "    posterior_name = posterior_data.name\n",
    "    posterior_hdi = az.hdi(posterior_data, hdi_prob=hdi_prob)\n",
    "    plot_data = pd.DataFrame(\n",
    "        {\n",
    "            \"predictor\": predictor_data,\n",
    "            \"mean\": posterior_data.mean(dim=[\"chain\", \"draw\"]),\n",
    "            \"hdi_lower\": posterior_hdi[posterior_name].sel(hdi=\"lower\"),\n",
    "            \"hdi_higher\": posterior_hdi[posterior_name].sel(hdi=\"higher\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if posterior_predictive_data is not None:\n",
    "        pp_name = posterior_predictive_data.name\n",
    "        pp_hdi = az.hdi(posterior_predictive_data, hdi_prob=hdi_prob)\n",
    "        plot_data[\"pp_hdi_lower\"] = pp_hdi[pp_name].sel(hdi=\"lower\")\n",
    "        plot_data[\"pp_hdi_higher\"] = pp_hdi[pp_name].sel(hdi=\"higher\")\n",
    "\n",
    "    plot_data.sort_values(\"predictor\", inplace=True)\n",
    "\n",
    "    # posterior mean\n",
    "    ax.plot(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"mean\"],\n",
    "        color=\"k\",\n",
    "    )\n",
    "\n",
    "    # posterior hdi\n",
    "    ax.fill_between(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"hdi_lower\"],\n",
    "        plot_data[\"hdi_higher\"],\n",
    "        color=\"k\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    if posterior_predictive_data is not None:\n",
    "        ax.fill_between(\n",
    "            plot_data[\"predictor\"],\n",
    "            plot_data[\"pp_hdi_lower\"],\n",
    "            plot_data[\"pp_hdi_higher\"],\n",
    "            color=\"k\",\n",
    "            alpha=0.1,\n",
    "        )\n",
    "\n",
    "    ax.set(title=\"Posterior predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ff9c-e9b4-4f1e-86f8-a7c264ad9a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "plot_posterior_predictions(\n",
    "    trace_5h3.constant_data.M,\n",
    "    trace_5h3.posterior.mu_N,\n",
    "    outcome_data=trace_5h3.observed_data.N,\n",
    "    posterior_predictive_data=trace_5h3.posterior_predictive.N,\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_title(\"Regression of N on M\")\n",
    "\n",
    "plot_posterior_predictions(\n",
    "    trace_5h3.constant_data.M,\n",
    "    trace_5h3.posterior_predictive.mu_K,\n",
    "    outcome_data=trace_5h3.observed_data.K,\n",
    "    posterior_predictive_data=trace_5h3.posterior_predictive.K,\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[1].set_title(\"Regression of K on M (and N)\")\n",
    "\n",
    "fig.suptitle(\"Posterior predictive\")\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab580301-7086-4a6a-95bd-7fc388936835",
   "metadata": {},
   "source": [
    "Now let's estimate the counterfactuals.\n",
    "The question asks for the counterfactual for doubling $M$, which is the standardised log mass.\n",
    "This seems a little strange to me (by definition the mean of $M$ is zero so doubling it will have no effect), so I'll look at the counterfactual effect of doubling the actual mass instead. Due to properties of logarithms this is equivalent to adding `ln(2) / std(log_mass)` to $M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c578f2-a1df-45fd-8d5e-6f495d431da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delta_M = milk_normaliser.var_[feature_cols.index(\"log_mass\")]\n",
    "print(delta_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116130d-586f-441c-8f9d-451159c34bb3",
   "metadata": {},
   "source": [
    "Our back of the envelope estimate earlier suggests that this should roughly decrease $K$ by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e674b36-4ba5-4f33-bd45-00ae9a84ef5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(round(delta_M * 0.3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba46d2-85e6-4a9e-b7e5-e0bcead21580",
   "metadata": {},
   "source": [
    "I believe the effect of this should be constant (i.e. independent of that values of $M$ and $N$) but lets generate full counterfactuals for the data to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ae942-56a7-48e6-be4f-b03cbbd76126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with m_5h3:\n",
    "    pm.set_data({\"M\": milk.M + delta_M})\n",
    "    trace_5h3 = pm.sample_posterior_predictive(\n",
    "        trace_5h3,\n",
    "        extend_inferencedata=True,\n",
    "        predictions=True,\n",
    "        random_seed=RANDOM_SEED,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddec3bf-40f5-4d76-be63-4da397157d46",
   "metadata": {},
   "source": [
    "Now look at the expected change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060f3f2-0ca4-4d2a-a538-609cfcdcdcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_5h3.predictions[\"K_counterfactual_change\"] = (\n",
    "    trace_5h3.predictions.K - trace_5h3.posterior_predictive.K\n",
    ")\n",
    "\n",
    "az.summary(\n",
    "    trace_5h3,\n",
    "    var_names=\"K_counterfactual_change\",\n",
    "    group=\"predictions\",\n",
    "    kind=\"stats\",\n",
    "    hdi_prob=0.89,\n",
    "    round_to=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6aa02-292a-43db-a134-10bbf37e36bf",
   "metadata": {},
   "source": [
    "As expected, this has no dependence on the original values of $M$ and $N$.\n",
    "Finally let's un-normalise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117c06b-c4b0-4405-8842-36ec66cbb8ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K_idx = normed_feature_cols.index(\"K\")\n",
    "K_counterfactual_change = trace_5h3.predictions.K_counterfactual_change.isel(species=0)\n",
    "kcal_per_g_counterfactual_change = K_counterfactual_change * milk_normaliser.mean_[\n",
    "    K_idx\n",
    "] + np.sqrt(milk_normaliser.var_[K_idx])\n",
    "kcal_per_g_counterfactual_change.name = \"kcal_per_g_counterfactual_change\"\n",
    "\n",
    "az.summary(kcal_per_g_counterfactual_change, kind=\"stats\", hdi_prob=0.89, round_to=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c607f-1d23-41b3-ad8a-d4d7add10264",
   "metadata": {},
   "source": [
    "So we can answer the question simply: the counterfactual effect of doubling mass is an expected change in `kcal_per_g` of -0.33 with a 89% HDI of (-0.96, 0.23).\n",
    "\n",
    "Note: this is actually a very wide interval - we expected that this would only actually decrease `kcal_per_g` 81% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43604c-1c85-420f-bc6f-b7a9c014ad71",
   "metadata": {},
   "source": [
    "### 5H4\n",
    "\n",
    "Here is an open practice problem to engage your imagination.\n",
    "In the divorce data, States in the southern United States have many of the highest divorce rates.\n",
    "Add the South indicator variable to the analysis.\n",
    "First, draw one or more DAGs that represent your ideas for how Southern American culture might influence any of the other three variables ($D$, $M$, or $A$).\n",
    "Then list the testable implications of your DAGs, if there are any, and fit one or more models to evaluate the implications.\n",
    "What do you think the influence of “Southerness” is?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520282f2-9e94-4ba5-a705-84b5b01454c4",
   "metadata": {},
   "source": [
    "Letting $S$ denote 'Southerness', I expect that this has a causal effect on both $M$ and $A$, but not $D$.\n",
    "Combining this with the model from the book, this gives the following DAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a298ed-ccd6-4386-b2ee-6f2a52bd0818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = gr.Digraph()\n",
    "g.edge(\"S\", \"A\")\n",
    "g.edge(\"S\", \"M\")\n",
    "g.edge(\"A\", \"M\")\n",
    "g.edge(\"A\", \"D\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a0c0f-e7e0-47ae-b712-fed74787eaf8",
   "metadata": {},
   "source": [
    "The main testable implication of this DAG is that $S$ is conditionally independent of $D$ given $A$.\n",
    "\n",
    "Let's start by reimporting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab0dfa-023d-43c6-bb37-0401cf7b8756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "waffle = load_data(WAFFLE_DIVORCE_FILE, delimiter=\";\")\n",
    "\n",
    "# standardise variables\n",
    "waffle_normaliser = StandardScaler().set_output(transform=\"pandas\")\n",
    "waffle[[\"divorce\", \"marriage\", \"age\"]] = waffle_normaliser.fit_transform(\n",
    "    waffle[[\"Divorce\", \"Marriage\", \"MedianAgeMarriage\"]]\n",
    ")\n",
    "waffle.rename(columns={\"South\": \"south\"}, inplace=True)\n",
    "\n",
    "waffle[\"north_south\"] = np.where(\n",
    "    waffle[\"south\"] == 0,\n",
    "    \"north\",\n",
    "    \"south\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c26ed7-a83e-4035-afee-bbadd95134d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that we already showed in the text that $D$ is conditionally independent of $M$ given $D$, so if we're only interested in $D$ then we can completely ignore $M$.\n",
    "To test the implications of the DAG I'll first train a univariate model for $D$ on $A$ and compare this with a multivariate model on both $A$ and $S$.\n",
    "I'm also going to widen the prior on $\\beta$ a little - I think it's too tight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c83e49c-73a0-4e53-8926-79ad628f3f62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A -> D\n",
    "coords = {\n",
    "    \"state\": waffle.Location,\n",
    "}\n",
    "with pm.Model(coords=coords) as m_5h4a:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2)\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=1.5)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle.age, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_age * age, dims=\"state\")\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # inference button\n",
    "    trace_5h4a = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "m_5h4a.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86c6af-12ce-4323-a236-55431015290e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A,S -> D\n",
    "coords = {\"state\": waffle.Location, \"north_south\": [\"north\", \"south\"]}\n",
    "with pm.Model(coords=coords) as m_5h4b:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2, dims=\"north_south\")\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=1.5)\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle.age, dims=\"state\")\n",
    "    south_idx = pm.MutableData(\"south_idx\", waffle.south, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha[south_idx] + beta_age * age, dims=\"state\")\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # inference button\n",
    "    trace_5h4b = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "m_5h4b.to_graphviz()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4d676-6b32-48b7-abb5-eef782546119",
   "metadata": {},
   "source": [
    "Let's compare the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de6ee0-38f1-4cea-9e17-4116a4449440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    [trace_5h4a, trace_5h4b],\n",
    "    model_names=[\"m_5h4a\", \"m_5h4b\"],\n",
    "    var_names=[\"alpha\", \"beta_age\"],\n",
    "    combined=True,\n",
    "    hdi_prob=0.89,\n",
    "    figsize=(6, 1.5),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3eb51-54a3-48c3-ab30-63f69e2ec166",
   "metadata": {},
   "source": [
    "I would say that this gives some support to the claim that $D$ is conditionally independent of $S$ given $A$ - the $\\alpha$ values for the model that includes $S$ aren't very different from zero which lies in reasonal HDI.\n",
    "\n",
    "To understand the models better I want to plot and compare the posterior predictions. For the model that includes $S$ I want to compare the regression lines for Northern and Southern states so I will generate counterfactual predictions for the states all being Northern and all being Southern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d7c5e-b958-4f80-9bc9-6dd6dfe5ccc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_north_south_counterfactual_predictions(model, trace, n_states=50):\n",
    "    ns_traces = {}\n",
    "    with model:\n",
    "        pm.set_data(\n",
    "            {\n",
    "                \"south_idx\": np.zeros(50).astype(int),\n",
    "            }\n",
    "        )\n",
    "        ns_traces[\"north\"] = pm.sample_posterior_predictive(\n",
    "            trace,\n",
    "            var_names=[\"mu\", \"divorce\"],\n",
    "            random_seed=RANDOM_SEED,\n",
    "        )\n",
    "\n",
    "        pm.set_data(\n",
    "            {\n",
    "                \"south_idx\": np.ones(50).astype(int),\n",
    "            }\n",
    "        )\n",
    "        ns_traces[\"south\"] = pm.sample_posterior_predictive(\n",
    "            trace,\n",
    "            var_names=[\"mu\", \"divorce\"],\n",
    "            random_seed=RANDOM_SEED,\n",
    "        )\n",
    "\n",
    "    return ns_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cee16-2bba-4c23-8514-5b95c1bbfb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ns_traces_5h4b = generate_north_south_counterfactual_predictions(m_5h4b, trace_5h4b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd83153-a002-423b-ade6-0668dae2c961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_posterior_mean_and_hdi(\n",
    "    predictor_data, posterior_data, color=\"k\", hdi_prob=0.89, ax=None\n",
    "):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "    posterior_name = posterior_data.name\n",
    "    hdi = az.hdi(posterior_data, hdi_prob=0.89)\n",
    "    plot_data = pd.DataFrame(\n",
    "        {\n",
    "            \"predictor\": predictor_data,\n",
    "            \"mean\": posterior_data.mean(dim=[\"chain\", \"draw\"]),\n",
    "            \"hdi_lower\": hdi[posterior_name].sel(hdi=\"lower\"),\n",
    "            \"hdi_higher\": hdi[posterior_name].sel(hdi=\"higher\"),\n",
    "        }\n",
    "    ).sort_values(\"predictor\")\n",
    "\n",
    "    ax.plot(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"mean\"],\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "    ax.fill_between(\n",
    "        plot_data[\"predictor\"],\n",
    "        plot_data[\"hdi_lower\"],\n",
    "        plot_data[\"hdi_higher\"],\n",
    "        color=color,\n",
    "        alpha=0.3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974235be-ff56-445b-9d92-2ad60eeaa049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_divorce_model_with_and_without_southerness(\n",
    "    waffle_data, univariate_trace, ns_traces, hdi_prob=0.89, ax=None\n",
    "):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    hue_order = [\"north\", \"south\"]\n",
    "    sns.scatterplot(\n",
    "        data=waffle_data,\n",
    "        x=\"age\",\n",
    "        y=\"divorce\",\n",
    "        hue=\"north_south\",\n",
    "        hue_order=hue_order,\n",
    "    )\n",
    "\n",
    "    # plot univariate model\n",
    "    plot_posterior_mean_and_hdi(waffle_data.age, univariate_trace.posterior.mu, ax=ax)\n",
    "\n",
    "    # plot models with southernness\n",
    "    for north_south, trace in ns_traces.items():\n",
    "        color_idx = hue_order.index(north_south)\n",
    "        color = colors[color_idx]\n",
    "        plot_posterior_mean_and_hdi(\n",
    "            waffle_data.age, trace.posterior_predictive.mu, color=color, ax=ax\n",
    "        )\n",
    "\n",
    "    ax.set(title=\"Posterior predictions with and without Southernness\")\n",
    "    ax.legend(title=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f472984-1edd-4d94-b0cf-251ad85e7118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_divorce_model_with_and_without_southerness(waffle, trace_5h4a, ns_traces_5h4b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aba71f-412c-4e6b-a072-411f833ca733",
   "metadata": {},
   "source": [
    "You can see that including Southerness as a feature hasn't made much difference to the regression lines.\n",
    "But, it also looks like the North/South regression lines don't fit that well.\n",
    "This is probably because they are constrained to have the same slope.\n",
    "Let's see if we can do better if we add an interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7dad3d-d341-4714-b60e-6a763cba0daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with interaction term\n",
    "coords = {\"state\": waffle.Location, \"north_south\": [\"north\", \"south\"]}\n",
    "with pm.Model(coords=coords) as m_5h4c:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2, dims=\"north_south\")\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=1.5, dims=\"north_south\")\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle.age, dims=\"state\")\n",
    "    south_idx = pm.MutableData(\"south_idx\", waffle.south, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\n",
    "        \"mu\", alpha[south_idx] + beta_age[south_idx] * age, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # inference button\n",
    "    trace_5h4c = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "m_5h4c.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706a622-2781-4035-a4ec-94d54b77865f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    [trace_5h4a, trace_5h4b, trace_5h4c],\n",
    "    model_names=[\"m_5h4a\", \"m_5h4b\", \"m_5h4c\"],\n",
    "    var_names=[\"alpha\", \"beta_age\"],\n",
    "    combined=True,\n",
    "    hdi_prob=0.89,\n",
    "    figsize=(6, 2),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5c6a6-173d-4372-ad56-711408fee207",
   "metadata": {},
   "source": [
    "This looks much better.\n",
    "The Southern age slope is significantly different from either the Northern slope or the univariate model.\n",
    "\n",
    "Let's plot the posterior predictions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40c0cb-a3a1-44e6-819a-39a0d0145204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ns_traces_5h4c = generate_north_south_counterfactual_predictions(m_5h4c, trace_5h4c)\n",
    "plot_divorce_model_with_and_without_southerness(waffle, trace_5h4a, ns_traces_5h4c)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set(ylim=[-2.5, 2.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16caafe1-1221-4f31-bf27-6a8cdcf6c19d",
   "metadata": {},
   "source": [
    "That certainly looks a lot better and you can tell that Southerness has a strong impact on the slope.\n",
    "\n",
    "It actually looks like there isn't much dependence of the intercept on Southerness.\n",
    "For a final model I'll remove that term and just keep the interaction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1ce04-f388-40e8-81f7-0f55bedd6d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with interaction term\n",
    "coords = {\"state\": waffle.Location, \"north_south\": [\"north\", \"south\"]}\n",
    "with pm.Model(coords=coords) as m_5h4d:\n",
    "    # priors\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=0.2)\n",
    "    beta_age = pm.Normal(\"beta_age\", mu=0, sigma=1.5, dims=\"north_south\")\n",
    "    sigma = pm.Exponential(\"sigma\", lam=1)\n",
    "\n",
    "    # data\n",
    "    age = pm.MutableData(\"age\", waffle.age, dims=\"state\")\n",
    "    south_idx = pm.MutableData(\"south_idx\", waffle.south, dims=\"state\")\n",
    "\n",
    "    # linear model\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta_age[south_idx] * age, dims=\"state\")\n",
    "\n",
    "    # likelihood\n",
    "    divorce = pm.Normal(\n",
    "        \"divorce\", mu=mu, sigma=sigma, observed=waffle.divorce, dims=\"state\"\n",
    "    )\n",
    "\n",
    "    # inference button\n",
    "    trace_5h4d = pm.sample(random_seed=RANDOM_SEED)\n",
    "\n",
    "\n",
    "m_5h4d.to_graphviz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005ec11-9630-48f8-a501-48bc6a238123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    [trace_5h4a, trace_5h4b, trace_5h4c, trace_5h4d],\n",
    "    model_names=[\"m_5h4a\", \"m_5h4b\", \"m_5h4c\", \"m_5h4d\"],\n",
    "    var_names=[\"alpha\", \"beta_age\"],\n",
    "    combined=True,\n",
    "    hdi_prob=0.89,\n",
    "    figsize=(6, 2.5),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b68a07-df0c-458a-a575-f60fa8191448",
   "metadata": {},
   "source": [
    "This hasn't really made much difference to the slope values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4666742-d445-4a3d-a3ef-b2329a8e5095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ns_traces_5h4d = generate_north_south_counterfactual_predictions(m_5h4d, trace_5h4d)\n",
    "plot_divorce_model_with_and_without_southerness(waffle, trace_5h4a, ns_traces_5h4d)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set(ylim=[-2.5, 2.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe2cc0-ba1a-4a7a-8777-d80ea6ea48d1",
   "metadata": {},
   "source": [
    "I think this looks like a really good fit.\n",
    "The only improvement I can see is that the variance around the regression line for Southern states looks less than for the Northern states.\n",
    "\n",
    "The conclusion is that our DAG was incorrect: there is a strong dependence of divorce rate on Southerness even accounting for age.\n",
    "More precisely, divorce rate decreases with median marriage age and this decrease is much stronger in Southern states.\n",
    "That is, Southern states where people marry young have much higher divorce rates than such Northern states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa6b0c-7dc3-4081-9812-c285d5a26cab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
